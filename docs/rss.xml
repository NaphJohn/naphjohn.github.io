<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>kaikai的博客</title><link>https://naphjohn.github.io</link><description>记录深度学习，大模型中技术感悟</description><copyright>kaikai的博客</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://avatars.githubusercontent.com/u/46772304?v=4</url><title>avatar</title><link>https://naphjohn.github.io</link></image><lastBuildDate>Mon, 15 Sep 2025 15:50:15 +0000</lastBuildDate><managingEditor>kaikai的博客</managingEditor><ttl>60</ttl><webMaster>kaikai的博客</webMaster><item><title>简历对应问题</title><link>https://naphjohn.github.io/post/jian-li-dui-ying-wen-ti.html</link><description>## 昇腾 NPU 深度优化
#### Q：• 请量化说明你在 **Page-Attention 上具体改**了哪几行代码/哪几个 kernel，15% 内存节省是如何测出来的？


A：把原来一次性为每个 seq 预分配 max_seq_len 的 KV Cache，改成按页（page=16 tokens）按需申请。</description><guid isPermaLink="true">https://naphjohn.github.io/post/jian-li-dui-ying-wen-ti.html</guid><pubDate>Mon, 15 Sep 2025 15:49:42 +0000</pubDate></item><item><title>SGlang推理引擎</title><link>https://naphjohn.github.io/post/SGlang-tui-li-yin-qing.html</link><description>## SGlang框架
1. **前端语言**：
   - 提供原生成API接口，可以直接与本地模型交互和调用。</description><guid isPermaLink="true">https://naphjohn.github.io/post/SGlang-tui-li-yin-qing.html</guid><pubDate>Tue, 09 Sep 2025 12:10:55 +0000</pubDate></item><item><title>算子测精度差异</title><link>https://naphjohn.github.io/post/suan-zi-ce-jing-du-cha-yi.html</link><description># 算子介绍
### reducescatter算子
ReduceScatter 是一个在大规模并行计算（尤其是深度学习训练）中非常重要的集合通信（Collective Communication）算子。</description><guid isPermaLink="true">https://naphjohn.github.io/post/suan-zi-ce-jing-du-cha-yi.html</guid><pubDate>Tue, 09 Sep 2025 07:05:38 +0000</pubDate></item><item><title>深度学习基础</title><link>https://naphjohn.github.io/post/shen-du-xue-xi-ji-chu.html</link><description># CNN

**关键组件：**
  - 卷积层： 提取局部特征，使用滤波器（Filter）滑动计算。</description><guid isPermaLink="true">https://naphjohn.github.io/post/shen-du-xue-xi-ji-chu.html</guid><pubDate>Tue, 09 Sep 2025 03:24:30 +0000</pubDate></item><item><title>生成模型</title><link>https://naphjohn.github.io/post/sheng-cheng-mo-xing.html</link><description>## Diffusion Models 扩散模型
核心思想是逐步的数据生成过程。</description><guid isPermaLink="true">https://naphjohn.github.io/post/sheng-cheng-mo-xing.html</guid><pubDate>Tue, 09 Sep 2025 01:39:45 +0000</pubDate></item><item><title>linux</title><link>https://naphjohn.github.io/post/linux.html</link><description>
初始化设置
```python
vim ~/.bashrc

export HISTSIZE=1000
export ASCEND_RT_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export https_proxy=http://10.155.192.138:8080
``` 

### 修改pip源
```powershell
vim ~/.pip/pip.conf
[global]
index-url = http://7.223.199.227/pypi/simple
trusted-host = 7.223.199.227
timeout = 120

#pip install torch==2.5.1  --default-timeout=1000 -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com
``` 

### 多机启动
```powershell
ray：# 指定通信网卡，使用ifconfig查看，找到和主机IP一致的网卡名
export GLOO_SOCKET_IFNAME=enp67s0f5
export TP_SOCKET_IFNAME=enp67s0f5
export RAY_EXPERIMENTAL_NOSET_ASCEND_RT_VISIBLE_DEVICES=1
export ASCEND_RT_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

export MM_ALL_REDUCE_OP_THRESHOLD=1000000
export HCCL_OP_EXPANSION_MODE='AIV'
export NUMEXPR_MAX_THREADS=192

# 将其中一个节点设为头节点
ray start --head --num-gpus=8
# 在其他节点执行
ray start --address='7.216.55.58:6379' --num-gpus=8
``` 


### 远程链接容器
```powershell
#配置ssh
#第一步config文件
vi /etc/ssh/sshd_config
PermitRootLogin yes
PasswordAuthentication yes
#第二步建立/run/sshd
mkdir /run/sshd

#第三步确认没有sshd时候设置passwd
passwd #这个时候别有sshd
#第四步开启sshd
/usr/sbin/sshd
ssh 7.242.105.173 -p 8035 #来确认是否链接成功

#解决上面报错，生成对应ssh
ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key -P '' -q
ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -P '' -q
ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key -P '' -q

#不需要ssh命令
git config --global http.sslVerify false

#支持自动迁移代码
 from torch_npu.contrib import transfer_to_npu
``` 

### 查看cann包
```powershell
#查看cann包版本
cat /usr/local/Ascend/ascend-toolkit/latest/version.cfg
#去除所有进程
ps -ef | grep python| grep -v grep | awk '{print $2}' | xargs kill -9
#pytorch中查看日志的两行命令
export ASCEND_GLOBAL_LOG_LEVEL=1
export ASCEND_SLOG_PRINT_TO_STDOUT=1
``` 

### 可视化数据
```powershell
# 使用 pip3 (推荐)
pip3 install visidata

# Ubuntu/Debian
sudo apt-get install visidata

# macOS (使用Homebrew)
brew install visidata


vd + csv文件
``` 。</description><guid isPermaLink="true">https://naphjohn.github.io/post/linux.html</guid><pubDate>Mon, 08 Sep 2025 07:22:10 +0000</pubDate></item><item><title>CLIP模型</title><link>https://naphjohn.github.io/post/CLIP-mo-xing.html</link><description># CLIP


## CLIP训练
CLIP（Contrastive Language–Image Pre-training）的训练方式非常巧妙，其核心是对比学习（Contrastive Learning）。</description><guid isPermaLink="true">https://naphjohn.github.io/post/CLIP-mo-xing.html</guid><pubDate>Mon, 08 Sep 2025 03:11:11 +0000</pubDate></item><item><title>RAG</title><link>https://naphjohn.github.io/post/RAG.html</link><description>1. 什么是rag？
2. rag流程？
3.rag优化点？
4.基座选取标准？
手撕算法：1.并查集 2.最大二叉树宽度


### RAG 怎么解决模型幻觉？
1. grounding（ grounding 生成过程）
- 原理：RAG在让模型生成答案之前，会先从外部知识库（如文档、数据库、网页）中检索出与问题最相关的信息片段（Context）。</description><guid isPermaLink="true">https://naphjohn.github.io/post/RAG.html</guid><pubDate>Mon, 08 Sep 2025 02:54:13 +0000</pubDate></item><item><title>Code</title><link>https://naphjohn.github.io/post/Code.html</link><description>## 数组
数组是存放在连续内存空间上的相同类型数据的集合。</description><guid isPermaLink="true">https://naphjohn.github.io/post/Code.html</guid><pubDate>Sat, 06 Sep 2025 13:59:33 +0000</pubDate></item><item><title>大模型推理基础</title><link>https://naphjohn.github.io/post/da-mo-xing-tui-li-ji-chu.html</link><description># LLM的推理/transformer架构/vllm

## LLM 推理的推理过程
目前主流LLM都是基于transformer的Decoder-only架构，因为 Decoder-only 架构**在“大规模无监督预训练”这个特定范式下，展现出了更好的可扩展性（Scalability）和任务通用性。</description><guid isPermaLink="true">https://naphjohn.github.io/post/da-mo-xing-tui-li-ji-chu.html</guid><pubDate>Sat, 06 Sep 2025 13:42:06 +0000</pubDate></item><item><title>大模型推理加速算法</title><link>https://naphjohn.github.io/post/da-mo-xing-tui-li-jia-su-suan-fa.html</link><description># 大模型优化方式/优化特性

### 量化
目的是对模型压缩与加速。</description><guid isPermaLink="true">https://naphjohn.github.io/post/da-mo-xing-tui-li-jia-su-suan-fa.html</guid><pubDate>Sat, 06 Sep 2025 13:36:25 +0000</pubDate></item><item><title>训练</title><link>https://naphjohn.github.io/post/xun-lian.html</link><description>
## 提高推理能力方法
&lt;details&gt;&lt;summary&gt;Details&lt;/summary&gt;
&lt;p&gt;

哪些提高推理能力的方法
提高推理能力需要从数据、训练方法、模型架构和推理策略等多个层面入手。</description><guid isPermaLink="true">https://naphjohn.github.io/post/xun-lian.html</guid><pubDate>Sat, 06 Sep 2025 13:21:04 +0000</pubDate></item></channel></rss>