最新deepseek创新：
DeepSeek 在 V3.2-Exp 里把 DSA（DeepSeek Sparse Attention）做成**“一套可插拔的细粒度动态稀疏框架”**，核心优化可以概括为 4 句话、8 个关键词，对应 4 组实测收益——全部在 128 K 长度下验证，且**零 checkpoint 转换、即插即用**。

------------------------------------------------
1. 局部-全局分层掩码  
   - 局部：滑动窗口 512，计算量 O(n·w)  
   - 全局：按“梯度-熵”混合分数在线采样 10 % token，计算量 O(n·0.1n)→Õ(n)  
   - 结果：注意力 FLOPs 从 n²→n·log n，128 K 推理速度↑3.2×，峰值显存↓67 % 

2. 闪电索引器 + Top-k 精算  
   - 粗筛：轻量级 CNN 扫一遍隐状态，50 ns 内给出 2 % 候选位置索引  
   - 精算：只对候选位置做完整 QK^⊤，其余直接填 0；稀疏度 98 % 时仍保持 99.2 % 原始 logits 排序  
   - 结果：预填充（prefill）阶段单卡 H800 上 128 K 序列从 42 s→13 s 

3. 动态门控融合  
   - 门控网络输入“全局语义向量”，输出 local / global 权重 λ∈[0,1]  
   - 训练目标加 L1 稀疏正则，保证 λ 自动趋向最稀疏可接受值  
   - 结果：相同训练步数下准确率波动幅度比稠密基线减小 63 %，收敛更稳 

4. 稀疏-稠密平滑迁移  
   - 两阶段训练：先稠密 warmup 95 % 步数→再开稀疏 finetune 5 %  
   - 无需重训大权重，只对门控和 Top-k 路由层更新；原 V3.1-Terminus  checkpoint 直接继承  
   - 结果：公开 benchmark 上平均得分与稠密版持平（差值≤0.3 %），API 成本直降 50 % 

------------------------------------------------
一句话总结  
DSA 通过“**局部窗口+在线采样+门控融合**”三条策略，把 Attention 计算从稠密 n² 变成**可学习的 2 % 稀疏度**，在 128 K 长度下实现**推理 3× 提速、显存 67 % 节省、精度 0.3 % 以内波动**，并且能零成本迁移已有稠密权重——这就是 DeepSeek 给出的全部优化点。